{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e975bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import random\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from imblearn.over_sampling import ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7338bbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7849, 2048)\n",
      "1013\n",
      "(1379, 2048)\n",
      "1013\n",
      "7849\n",
      "1379\n"
     ]
    }
   ],
   "source": [
    "#This function is used to encode labels since labels are categorical.\n",
    "def encode_labels(labels):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(labels)\n",
    "    encoded_labels = le.transform(labels)\n",
    "    \n",
    "    return encoded_labels, le\n",
    "\n",
    "def decode_labels(encoded_predict_labels, le):\n",
    "    test_predictions = le.inverse_transform(encoded_predict_labels)\n",
    "    \n",
    "    return test_predictions\n",
    "\n",
    "#Load data\n",
    "train = sio.loadmat('train.mat')\n",
    "validation = sio.loadmat('validation.mat')\n",
    "test = sio.loadmat('test_wolabels.mat')\n",
    "\n",
    "train_classid = np.squeeze(train['classid'])\n",
    "train_class_labels = []\n",
    "for item in train_classid:\n",
    "    train_class_labels.append(item[0])\n",
    "train_features = train['features']\n",
    "train_imid = train['imid']\n",
    "train_sampleid = train['sampleid']\n",
    "print(train_features.shape)\n",
    "train_unique_labels = sorted(np.unique(train_class_labels))\n",
    "train_unique_labels_count = len(train_unique_labels)\n",
    "print(train_unique_labels_count)\n",
    "\n",
    "validation_classid = np.squeeze(validation['classid'])\n",
    "validation_class_labels = []\n",
    "for item in validation_classid:\n",
    "    validation_class_labels.append(item[0])\n",
    "validation_features = validation['features']\n",
    "validation_imid = validation['imid']\n",
    "validation_sampleid = validation['sampleid']\n",
    "print(validation_features.shape)\n",
    "validation_unique_labels = sorted(np.unique(validation_class_labels))\n",
    "validation_unique_labels_count = len(validation_unique_labels)\n",
    "print(validation_unique_labels_count)\n",
    "\n",
    "#encoded train labels\n",
    "train_labels, le = encode_labels(train_class_labels)\n",
    "print(len(train_labels))\n",
    "\n",
    "#encoded validation labels\n",
    "validation_labels = le.transform(validation_class_labels)\n",
    "print(len(validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66bb7505",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0-1 normalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scalar = MinMaxScaler()\n",
    "train_features_norm = scalar.fit_transform(train_features)\n",
    "validation_features_norm = scalar.transform(validation_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc737cd",
   "metadata": {},
   "source": [
    "Ridge Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9ba08f",
   "metadata": {},
   "source": [
    "alpha parameter 1 is optimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8153a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean class accuracy scores: 0.8042059463379261\n"
     ]
    }
   ],
   "source": [
    "clf = RidgeClassifier(class_weight = 'balanced', random_state=0)\n",
    "clf.fit(train_features_norm, train_labels)\n",
    "RidgeClassifier_predictions = clf.predict(validation_features_norm)\n",
    "score = clf.score(validation_features_norm, validation_labels)\n",
    "print(\"Mean class accuracy scores:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "785e70a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save predictions in an excel file\n",
    "output_df = pd.DataFrame(RidgeClassifier_predictions)\n",
    "output_df.to_csv('Task1_RidgeClassifier_predictions.csv', index=False,  header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae47df79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7829643209702438\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "matrix = confusion_matrix(validation_labels, RidgeClassifier_predictions)\n",
    "acc = matrix.diagonal()/matrix.sum(axis=1)\n",
    "print(sum(acc)/len(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4c3d4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#z-score normalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scalar = StandardScaler()\n",
    "train_features_norm = scalar.fit_transform(train_features)\n",
    "validation_features_norm = scalar.transform(validation_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0ff1c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy scores: 0.8063814358230602\n"
     ]
    }
   ],
   "source": [
    "clf = RidgeClassifier(class_weight = 'balanced', random_state=0)\n",
    "clf.fit(train_features_norm, train_labels)\n",
    "RidgeClassifier_predictions = clf.predict(validation_features_norm)\n",
    "score = clf.score(validation_features_norm, validation_labels)\n",
    "print(\"accuracy scores:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40c3f71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean class accuracy scores: 0.782750434823485\n"
     ]
    }
   ],
   "source": [
    "matrix = confusion_matrix(validation_labels, RidgeClassifier_predictions)\n",
    "acc = matrix.diagonal()/matrix.sum(axis=1)\n",
    "print(\"Mean class accuracy scores:\", sum(acc)/len(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691d070c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
